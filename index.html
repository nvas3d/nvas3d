<!DOCTYPE html>
<html>

<head>
    <meta charset="utf-8">
    <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
    <!-- Replace the content tag with appropriate information -->
    <!-- <meta name="description" content="DESCRIPTION META TAG">
    <meta property="og:title" content="SOCIAL MEDIA TITLE TAG" />
    <meta property="og:description" content="SOCIAL MEDIA DESCRIPTION TAG TAG" />
    <meta property="og:url" content="URL OF THE WEBSITE" /> -->
    <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
    <!-- <meta property="og:image" content="static/image/your_banner_image.png" />
    <meta property="og:image:width" content="1200" />
    <meta property="og:image:height" content="630" /> -->


    <!-- <meta name="twitter:title" content="TWITTER BANNER TITLE META TAG">
    <meta name="twitter:description" content="TWITTER BANNER DESCRIPTION META TAG"> -->
    <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
    <!-- <meta name="twitter:image" content="static/images/your_twitter_banner_image.png">
    <meta name="twitter:card" content="summary_large_image"> -->
    <!-- Keywords for your paper to be indexed by-->
    <meta name="keywords"
        content="novel-view acoustic synthesis, source localization, source separation, dereverberation">
    <meta name="viewport" content="width=device-width, initial-scale=1">


    <title>NOVEL-VIEW ACOUSTIC SYNTHESIS FROM 3D RECONSTRUCTED ROOMS</title>
    <!-- <link rel="icon" type="image/x-icon" href="static/images/favicon.ico"> -->
    <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">

    <link rel="stylesheet" href="static/css/bulma.min.css">
    <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
    <link rel="stylesheet" href="static/css/bulma-slider.min.css">
    <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
    <link rel="stylesheet" href="static/css/index.css">

    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
    <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
    <script defer src="static/js/fontawesome.all.min.js"></script>
    <script src="static/js/bulma-carousel.min.js"></script>
    <script src="static/js/bulma-slider.min.js"></script>
    <script src="static/js/index.js"></script>
</head>

<body>


    <section class="hero">
        <div class="hero-body">
            <div class="container is-max-desktop">
                <div class="columns is-centered">
                    <div class="column has-text-centered">
                        <h1 class="title is-1 publication-title">NOVEL-VIEW ACOUSTIC SYNTHESIS FROM 3D RECONSTRUCTED
                            ROOMS</h1>
                        <div class="is-size-5 publication-authors">
                            <!-- Paper authors -->
                            <!-- <span class="author-block">
                <a href="FIRST AUTHOR PERSONAL LINK" target="_blank">First Author</a><sup>*</sup>,</span>
              <span class="author-block">
                <a href="SECOND AUTHOR PERSONAL LINK" target="_blank">Second Author</a><sup>*</sup>,</span>
              <span class="author-block">
                <a href="THIRD AUTHOR PERSONAL LINK" target="_blank">Third Author</a>
              </span> -->
                        </div>

                        <!-- <div class="is-size-5 publication-authors">
              <span class="author-block">Institution Name<br>Conferance name and year</span>
              <span class="eql-cntrb"><small><br><sup>*</sup>Indicates Equal Contribution</small></span>
            </div> -->

                        <div class="column has-text-centered">
                            <div class="publication-links">
                                <!-- Arxiv PDF link -->
                                <!-- <span class="link-block">
                  <a href="https://arxiv.org/pdf/<ARXIV PAPER ID>.pdf" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                    </span>
                    <span>Paper</span>
                  </a>
                </span> -->

                                <!-- Supplementary PDF link -->
                                <!-- <span class="link-block">
                  <a href="static/pdfs/supplementary_material.pdf" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                    </span>
                    <span>Supplementary</span>
                  </a>
                </span> -->

                                <!-- Github link -->
                                <!-- <span class="link-block">
                  <a href="https://github.com/YOUR REPO HERE" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span> -->

                                <!-- ArXiv abstract Link -->
                                <!-- <span class="link-block">
                  <a href="https://arxiv.org/abs/<ARXIV PAPER ID>" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="ai ai-arxiv"></i>
                    </span>
                    <span>arXiv</span>
                  </a>
                </span> -->
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </section>


    <!-- Teaser video-->
    <section class="hero teaser">
        <div class="container is-max-desktop">
            <div class="hero-body">
                <video poster="" id="tree" controls height="100%">
                    <source src="static/videos/teaser.mp4" type="video/mp4">
                </video>
                <!-- <video poster="" id="tree" autoplay controls muted loop height="100%">
          <source src="static/videos/banner_video.mp4", type="video/mp4">
        </video> -->
                <!-- <img src="static/images/qualitative_webpage.pdf" alt="" /> -->
                <br>
                <h2 class="subtitle has-text-centered">
                    We investigate the benefit of combining blind audio recordings with 3D scene information for
                    novel-view
                    acoustic synthesis. Given audio recordings from 2--4 microphones and the 3D geometry and material of
                    a scene,
                    we estimate the sound anywhere in a scene containing multiple unknown sound sources, hence resulting
                    in
                    novel-view acoustic synthesis.
                </h2>
            </div>
        </div>
    </section>
    <!-- End teaser video -->

    <!-- Paper abstract -->
    <section class="section hero is-light">
        <div class="container is-max-desktop">
            <div class="columns is-centered has-text-centered">
                <div class="column is-four-fifths">
                    <h2 class="title is-3">Abstract</h2>
                    <div class="content has-text-justified">
                        <p>
                            We investigate the benefit of combining blind audio recordings with 3D scene information for
                            novel-view
                            acoustic synthesis. Given audio recordings from 2--4 microphones and the 3D geometry and
                            material of a
                            scene, we estimate the sound anywhere in a scene containing multiple unknown sound sources.
                            We
                            identify the main challenges of novel-view acoustic synthesis as sound source localization,
                            separation,
                            and dereverberation, and we introduce a method that jointly tackles these problems using 3D
                            scene
                            information. Our key observation is that the Room Impulse Response (RIR), derived from a 3D
                            reconstructed
                            room, provides valuable cues for the tasks. Our method outperforms existing methods designed
                            specifically
                            for the individual tasks, demonstrating the effectiveness of utilizing 3D visual
                            information. In a
                            simulated study using the Matterport3D-NVAS dataset, we achieve near 100% accuracy in source
                            localization, a PSNR of 26.44dB and a SDR of 14.23dB for source separation and
                            dereverberation, hence resulting in 25.55dB and a SDR of 14.20dB on novel-view acoustic
                            synthesis.
                        </p>
                    </div>
                </div>
            </div>
        </div>
    </section>
    <!-- End paper abstract -->

    <!-- Paper method -->
    <section class="section is-light">
        <div class="container is-max-desktop">
            <div class="columns is-centered has-text-centered">
                <div class="column">
                    <h2 class="title is-3">Method</h2>
                    <img src="static/images/idea_v5.png" alt="" />
                    <div class="content has-text-justified">
                        <p>
                            Given a 3D reconstructed room (a) and audio recordings from different microphones (c), we
                            estimate the
                            locations and dry sound of individual sound sources. (d) Our key observation is that when
                            deconvolving the
                            audio recordings with the impulse response from a specific source location, sound emitted
                            from the
                            location
                            will align across individual recordings whereas sound from other locations will not. (e) The
                            alignment of
                            audios across different microphones provides a strong cue for the network. (f) The table
                            shows the cosine
                            similarity between two received/delayed/deconvolved audios on 1000 scenes. (g) The cosine
                            similarity
                            between
                            deconvolved audios and our source detection results on an example scene.
                        </p>
                    </div>
                    <img src="static/images/qualitative_webpage.pdf" alt="" />
                </div>
            </div>
        </div>
    </section>
    <!-- End paper method -->

    <!-- guitar and different sound -->

    <!-- Results -->

    <section class="results">
        <p class="text">Results (guitar + guitar)</p>



        <div class="row">
            <div class="col">
                <p class="text">Received audio from microphone 1</p>
                <audio controls>
                    <source src="static/audios/receiver1.wav" type="audio/wav">
                </audio>
            </div>
            <div class="col">
                <p class="text">Received audio from microphone 2</p>
                <audio controls>
                    <source src="static/audios/receiver2.wav" type="audio/wav">
                </audio>
            </div>
            <div class="col">
                <p class="text">Received audio from microphone 3</p>
                <audio controls>
                    <source src="static/audios/receiver3.wav" type="audio/wav">
                </audio>
            </div>
            <div class="col">
                <p class="text">Received audio from microphone 4</p>
                <audio controls>
                    <source src="static/audios/receiver4.wav" type="audio/wav">
                </audio>
            </div>
        </div>


        <div class="row full-width">
            <p class="text">Scene overview</p>
            <img src="static/images/scene_overview.png" alt="" />
            <!-- <video poster="" controls>
                <source src="static/videos/input.mp4" type="video/mp4">
            </video> -->
        </div>



        <div class="row">
            <div class="col">
                <p class="text">Estimated dry sound of source 1</p>
                <audio controls>
                    <source src="static/audios/dry1.wav" type="audio/wav">
                </audio>
            </div>
            <div class="col">
                <p class="text">Estimated dry sound of source 2</p>
                <audio controls>
                    <source src="static/audios/dry2.wav" type="audio/wav">
                </audio>
            </div>
        </div>

        <div class="row">
            <div class="col">
                <p class="text">Ground-truth dry sound of source 1</p>
                <audio controls>
                    <source src="static/audios/dry1_gt.wav" type="audio/wav">
                </audio>
            </div>
            <div class="col">
                <p class="text">Ground-truth dry sound of source 2</p>
                <audio controls>
                    <source src="static/audios/dry2_gt.wav" type="audio/wav">
                </audio>
            </div>
        </div>

        <div class="row full-width-scale">
            <p class="text">Novel-view acoustic synthesis</p>
            <video poster="" controls>
                <source src="static/videos/nvas.mp4" type="video/mp4">
            </video>
        </div>

        <div class="row">
            <div class="col">
                <p class="text">Novel-view acoustic synthesis using separated source 1 only</p>
                <video poster="" controls>
                    <source src="static/videos/nvas_1.mp4" type="video/mp4">
                </video>
            </div>
            <div class="col">
                <p class="text">Novel-view acoustic synthesis using separated source 2 only</p>
                <video poster="" controls>
                    <source src="static/videos/nvas_2.mp4" type="video/mp4">
                </video>
            </div>
        </div>
    </section>
    <!-- End Results -->





    <!-- Video carousel -->
    <!-- <section class="hero is-small">
    <div class="hero-body">
      <div class="container">
        <h2 class="title is-3">Another Carousel</h2>
        <div id="results-carousel" class="carousel results-carousel">
          <div class="item item-video1">
            <video poster="" id="video1" autoplay controls muted loop height="100%">
              <source src="static/videos/carousel1.mp4" type="video/mp4">
            </video>
          </div>
          <div class="item item-video2">
            <video poster="" id="video2" autoplay controls muted loop height="100%">
              <source src="static/videos/carousel2.mp4" type="video/mp4">
            </video>
          </div>
          <div class="item item-video3">
            <video poster="" id="video3" autoplay controls muted loop height="100%">\
              <source src="static/videos/carousel3.mp4" type="video/mp4">
            </video>
          </div>
        </div>
      </div>
    </div>
  </section> -->
    <!-- End video carousel -->






    <!-- Paper poster -->
    <!-- <section class="hero is-small is-light">
    <div class="hero-body">
      <div class="container">
        <h2 class="title">Poster</h2>

        <iframe src="static/pdfs/sample.pdf" width="100%" height="550">
        </iframe>

      </div>
    </div>
  </section> -->
    <!--End paper poster -->


    <!--BibTex citation -->
    <!-- <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>BibTex Code Here</code></pre>
    </div>
  </section> -->
    <!--End BibTex citation -->


    <footer class="footer">
        <div class="container">
            <div class="columns is-centered">
                <div class="column is-8">
                    <div class="content">

                        <p>
                            This page was built using the <a
                                href="https://github.com/eliahuhorwitz/Academic-project-page-template"
                                target="_blank">Academic Project Page Template</a>.
                            <br> Placeholder mesh “Classic Microphone” (https://skfb.ly/6Aryq) by urbanmasque is
                            licensed under
                            Creative Commons Attribution (http://creativecommons.org/licenses/by/4.0/).
                            <br> Placeholder mesh "Bluetooth Speaker" (https://skfb.ly/6VLyL) by Ramanan is licensed
                            under Creative
                            Commons Attribution (http://creativecommons.org/licenses/by/4.0/).


                            <!-- <br> This website is licensed under a <a rel="license"
                                href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
                                Commons Attribution-ShareAlike 4.0 International License</a>. -->
                        </p>
                        <!-- Credit the CreatorGART230 - Microphone by TabbieCat is licensed under Creative Commons Attribution -->

                    </div>
                </div>
            </div>
        </div>
    </footer>

    <!-- Statcounter tracking code -->

    <!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

</body>

</html>